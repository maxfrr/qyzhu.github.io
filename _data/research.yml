- name: Thompson Sampling Algorithms for Gaussian Mean-Variance Bandits
  #link: maxqyzhu.github.io
  conference: Thirty-seventh International Conference on Machine Learning
  authors: Qiuyu Zhu, Vincent Y.F. Tan       
  link: https://proceedings.icml.cc/static/paper_files/icml/2020/1567-Paper.pdf
  description: The multi-armed bandit (MAB) problem is a classical learning task that exemplifies the exploration-exploitation tradeoff. However, standard formulations do not take into account risk. In online decision making systems, risk is a primary concern. In this regard, the mean-variance risk measure is one of the most common objective functions. Existing algorithms for mean-variance optimization in the context of MAB problems have unrealistic assumptions on the reward distributions. We develop Thompson Samplingstyle algorithms for mean-variance MAB and provide comprehensive regret analyses for Gaussian and Bernoulli bandits with fewer assumptions. Our algorithms achieve the best known regret bounds for mean-variance MABs and also attain the information-theoretic bounds in some parameter regimes. Empirical simulations show that our algorithms significantly outperform existing LCB-based algorithms for all risk tolerances.


- name: Risk-Constrained Thompson Sampling for CVaR Bandits
  #link: maxqyzhu.github.io
  authors: Joel Q. L. Chang, Qiuyu Zhu and Vincent Y. F. Tan     
  link: https://arxiv.org/abs/2011.08046
  description: In this paper, we consider a popular risk measure in quantitative finance known as the Conditional Value at Risk (CVaR). We explore the performance of a Thompson Sampling-based algorithm CVaR-TS under this risk measure. We provide comprehensive comparisons between our regret bounds with state-of-the-art L/UCB-based algorithms in comparable settings and demonstrate their clear improvement in performance. We also include numerical simulations to empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.
